{
  "hash": "67ee9956729b16987cd1df1c943ec7a6",
  "result": {
    "markdown": "---\ntitle: \"Estadística Descriptiva Bivarada\"\nauthor: \"Andreina Alamo\"\nformat:\n  revealjs:\n    theme: serif\n    center: true\n    logo: logo.png\n    css: logo.css\n    incremental: true \neditor: \n  markdown: \n    wrap: 72\n---\n\n\n## Introducción\n\nEn el capítulo anterior vimos que existen dos tipos de variables: cualitativas y cuantitativas. Ahora, cuando analizamos **2 variables** tenemos los siguientes posibles cruces:\n\n- Cualitativa - Cualitativa.\n- Cuantitativa - Cuantitativa.\n- Cualitativa - Cuantitativa.\n\n. . . \n\nCuando se analizan dos variables en conjunto este se denomina **bivariado**, y consiste en identificar patrones, nexos o asociaciones entre las dos variables del estudio.\n\n## Caso Cualitativa - Cualitativa\n\nEn este escenario se dispone de un conjunto de $n$ individuos, cada uno de ellos observado en dos atributos que en adelante se representan mediante $X$ y $Y$. Se supone que la variable $X$ tiene $k$ categorías, es decir, $X$ asume los valores $x_1,x_2,…,x_k$, y que la variable Y tiene p categorías, es decir, Y asume los valores $y_1,y_2,…,y_p$.\n\n## Frecuencia absoluta conjunta{.smaller}\n\nLa **frecuencia absoluta conjunta** de la clase $C_{i j}$, denotada con $n_{i j}$, es la cantidad de observaciones que hacen parte de la $i$-ésima fila y la $j$ -ésima columna para $i=1, \\ldots, k$ y $j=1, \\ldots, p$.\n\n|$X / Y$  | $y_1$         | $y_2$         | $\\cdots$ | $y_j$      | $\\cdots$   | $y_p$      | Total      |\n|--------:|--------------:|--------------:|---------:|-----------:|-----------:|-----------:|-----------:|\n|$x_1$    | $n_{11}$      | $n_{12}$      | $\\cdots$ | $n_{1 j}$  | $\\cdots$ | $n_{1 p}$    | $n_{1 .}$  |\n|$x_2$    | $n_{21}$      | $n_{22}$      | $\\cdots$ | $n_{2 j}$  | $\\cdots$ | $n_{2 p}$    | $n_{2 .}$  |\n|$\\vdots$ | $\\vdots$      | $\\vdots$      | $\\ddots$ | $\\vdots$   | $\\ddots$ | $\\vdots$     | $\\vdots$   | \n|$x_i$    | $n_{i 1}$     | $n_{i 2}$     | $\\cdots$ | $n_{i j}$  | $\\cdots$ | $n_{i p}$    |$n_{i \\cdot}$|\n|$\\vdots$ | $\\vdots$      | $\\vdots$      | $\\ddots$ | $\\vdots$   | $\\ddots$ | $\\vdots$     | $\\vdots$    |\n|$x_k$    | $n_{k 1}$     | $n_{k 2}$     | $\\cdots$ | $n_{k j}$  | $\\cdots$ | $n_{k p}$    |$n_{k \\cdot}$|\n|Total    | $n_{\\cdot 1}$ | $n_{\\cdot 2}$ | $\\cdots$ |$n_{\\cdot j}$| $\\cdots$| $n_{\\cdot p}$| $n$         |\n\n## Frecuencia relativa conjunta{.smaller}\n\nLa **frecuencia relativa conjunta** de la clase $C_{i j}$, denotada con $fr_{i j}$, es la proporción de la frecuencia absoluta conjunta de la $i j$-ésima categoría respecto a la cantidad total de observaciones, esto es: $fr_{i j}=\\frac{n_{i j}}{n}$\npara $i=1, \\ldots, k$ y $j=1, \\ldots, p$.\n\n|$X / Y$  | $y_1$         | $y_2$         | $\\cdots$ | $y_j$      | $\\cdots$ | $y_p$      | Total      |\n|--------:|--------------:|--------------:|---------:|-----------:|---------:|-----------:|-----------:|\n|$x_1$    | $fr_{11}$     | $fr_{12}$     | $\\cdots$ | $fr_{1 j}$ | $\\cdots$ | $fr_{1 p}$ | $fr_{1 \\bullet}$|\n|$x_2$    | $fr_{21}$     | $fr_{22}$     | $\\cdots$ | $fr_{2 j}$ | $\\cdots$ | $fr_{2 p}$ | $fr_{2 \\bullet}$|\n|$\\vdots$ | $\\vdots$      | $\\vdots$      | $\\ddots$ | $\\vdots$   | $\\ddots$ | $\\vdots$   | $\\vdots$   | \n|$x_i$    | $fr_{i 1}$    | $fr_{i 2}$    | $\\cdots$ | $fr_{i j}$ | $\\cdots$ | $fr_{i p}$ |$fr_{i \\bullet}$|\n|$\\vdots$ | $\\vdots$      | $\\vdots$      | $\\ddots$ | $\\vdots$   | $\\ddots$ | $\\vdots$   | $\\vdots$   |\n|$x_k$    | $fr_{k 1}$    | $fr_{k 2}$    | $\\cdots$ | $fr_{k j}$ | $\\cdots$ | $fr_{k p}$ |$fr_{k \\bullet}$|\n|Total    |$fr_{\\bullet 1}$|$fr_{\\bullet 2}$|$\\cdots$|$fr_{\\bullet j}$|$\\cdots$|$fr_{\\bullet p}$|$1$   |\n\n\nLa **frecuencia absoluta marginal** de la fila $i$, denotada con $n_{i \\bullet}$, es el total de observaciones de la $i$-ésima categoría de la variable de las filas para $i=1, \\ldots, k$.\n\n## {.smaller}\n\nAsí mismo, la **frecuencia absoluta marginal de la columna** $j$, denotada con $n_{\\bullet j}$, es el total de observaciones de la $j$-ésima categoría de la variable de las columnas para $j=1, \\ldots, p$.\n\nA partir de la definición se tiene que:\n\n$$\nn_{i \\bullet}=n_{i 1}+n_{i 2}+\\ldots+n_{i p}=\\sum_{j=1}^p n_{i j} \\quad \\text { para } i=1, \\ldots, k,\n$$\ny además,\n$$\nn_{\\bullet j}=n_{1 j}+n_{2 j}+\\ldots+n_{k j}=\\sum_{i=1}^k n_{i j} \\quad \\text { para } j=1, \\ldots, p .\n$$\n\nLas **frecuencias relativas marginales** se definen análogamente.\n\n## Ejemplo \n\nLa siguiente tabla corresponde a una tabla de contingencia en la que se estudia la variable sexo ($X$) y nivel educativo ($Y$) de una muestra de personas. Obtener las frecuencias relativas conjuntas y marginales correspondientes.\n\n|X/Y    |Bachillerato |\tPregrado|\tPosgrado|\t\n|-------|------------:|--------:|--------:|\n|Hombre\t|$4$         |$9$      |\t    $12$|\t \n|Mujer\t|$12$\t        |$7$      |\t     $2$|\n\n- Halle $k$,$p$,$n$,$n_{1\\bullet}$,$n_{2\\bullet}$,$n_{\\bullet 1}$,$n_{\\bullet 2}$ y $n_{\\bullet 3}$. \n- Cálcule la tabla de frecuencias relativas con sus respectivas frecuencias relativas marginales.\n\n## Solución{.smaller}\n\n$k=2, p=3, n_{1 \\bullet} =25, n_{2 \\bullet}=21, n_{\\bullet}=16, n_{\\bullet}=16, n_{\\bullet}=14 \\quad \\text { y } \\quad n=46$\n\n. . . \n\nLa tabla de frecuencias relatrivas es:\n\n| $X / Y$ | Bachillerato | Pregrado | Posgrado | Total |\n| -------| ----: | ----: | ----: | ----: |\n| Hombre | $8.7 \\%$ | $19.6 \\%$ | $26.1 \\%$ | $54.3 \\%$ |\n| Mujer | $26.1 \\%$ | $15.2 \\%$ | $4.3 \\%$ | $45.7 \\%$ |\n| Total | $34.8 \\%$ | $34.8 \\%$ | $30.4 \\%$ | $100.0 \\%$ |\n\n## Perfiles{.smaller}\n\nLos **perfiles fila** están asociados con una tabla de doble entrada en la que se calculan las frecuencias relativas conjuntas respecto a los totales de las filas correspondientes.\n\nAnálogamente, se definen los **perfiles columna**.\n\nA partir de la definición, se tiene que la frecuencia relativa de la $i j$-ésima categoría de una tabla de perfiles fila, denotada con $h_{i j \\mid \\bullet}$, está dada por:\n$$\nh_{i j \\mid i \\bullet}=\\frac{n_{i j}}{n_{i \\bullet}},\n$$\nmientras que la frecuencia relativa de la $i j$-ésima categoría de una tabla de perfiles columna, denotada con $h_{i j} \\bullet j$, se está dada por:\n$$\nh_{i j \\mid \\bullet j}=\\frac{n_{i j}}{n_{\\bullet j}}\n$$\n\npara $i=1, \\ldots, k$ y $j=1, \\ldots, p$.\n\n## Ejemplo \n\nSiguiendo con nuestro ejemplo anterior se tienen las siguientes tablas:\n\nPerfiles fila:\n\n| $X / Y$ | Bachillerato | Pregrado | Posgrado | Total |\n| --------| ----: | ----: | ----: | ----: |\n| Hombre | $16.0 \\%$ | $36.0 \\%$ | $48.0 \\%$ | $100.0 \\%$ |\n| Mujer | $57.1 \\%$ | $33.3 \\%$ | $9.5 \\%$ | $100.0 \\%$ |\n| Total | $34.8 \\%$ | $34.8 \\%$ | $30.4 \\%$ | $100.0 \\%$ |\n\n------------------------\n\nPerfiles columna:\n\n| $X / Y$ | Bachillerato | Pregrado | Posgrado |  |\n| ------- | ----: | ----: | ----: | ----: |\n| Hombre | $25.0 \\%$ | $56.3 \\%$ | $85.7 \\%$ | $54.3 \\%$ |\n| Mujer | $75.0 \\%$ | $43.8 \\%$ | $14.3 \\%$ | $45.7 \\%$ |\n| Total | $100.0 \\%$ | $100.0 \\%$ | $100.0 \\%$ | $100.0 \\%$ |\n\n## \n\nCuando se trabaja con dos variables cuantitativas, es costumbre denominar a la variable $X$ representada en el eje $x$ variable independiente y a la variable $Y$ representada en el eje $y$ variable dependiente.\n\nEs costumbre mostrar las observaciones de una muestra correspondiente a un conjunto de datos bivariado como sigue.\n\\begin{tabular}{ccc}\n$X$ & $Y$ & $y_1$ \\\\\n\\hline$x_1$ & $y_1$ & $\\vdots$ \\\\\n\\hline$x_1$ & $\\vdots$ & $y_n$\n\\end{tabular}\n\n## Gráficos para 2 varaibles cualitativas\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](3.-Descriptiva-Bivariada_files/figure-revealjs/perfiles fila-1.png){width=960}\n:::\n:::\n\n\n## \n\n::: {.cell}\n::: {.cell-output-display}\n![](3.-Descriptiva-Bivariada_files/figure-revealjs/perfiles columna-1.png){width=960}\n:::\n:::\n\n\n## \n\nCuando se trabaja con dos variables cuantitativas, es costumbre denominar a la variable $X$ representada en el eje $x$ variable independiente y a la variable $Y$ representada en el eje $y$ variable dependiente.\n\nEs costumbre mostrar las observaciones de una muestra correspondiente a un conjunto de datos bivariado como sigue.\n\n|$X$ | $Y$ | \n|-----:|------:|\n|$x_1$ | $y_1$ |\n|$x_2$ |$y_2$| \n|$\\vdots$ |$\\vdots$| \n|$x_n$ |$y_n$| \n\n\n\n# Caso Cuantitativa - Cuantitativa\n\n\nEn este escenario se dispone de un conjunto de $n$ individuos, en cada uno de ellos se observan dos variables cuantitativas que en adelante se representan mediante $X$ y $Y$.\n\n. . .\n\nEn este caso, es bueno iniciar el análisis realizando un **gráfico de dispersión**, es decir, un gráfico de puntos tal que cada eje (vertical y horizontal) corresponde a una de las dos variables en estudio.\n\n----\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](3.-Descriptiva-Bivariada_files/figure-revealjs/unnamed-chunk-1-1.png){width=960}\n:::\n:::\n\n\n##\n\nEn este gráfico se puede identificar si existe algún tipo de relación o (asociación) entre las dos variables y de qué tipo es. \n\n. . .\n\nSi al realizar el gráfico de dispersión los puntos no siguen ningún patrón, se toma como un indicio de que las variables son **independientes**, es decir, no están **correlacionadas**. En otro caso, se dice que están **correlacionadas**.\n\n. . .\n\nLa **correlación** entre las variables puede ser **lineal**, si los puntos siguen aproximadamente una recta, o **no lineal** en otro caso.\n\n---\n\nLa siguiente imagen muestra los tipos de relaciones que pueden existir entre las variables:\n\n<p align=\"center\">\n<img src=\"tipo_asociación.png\" width=\"450\">\n</p>\n\n## Covarianza\n\nPara medir el grado de asociación lineal entre dos variables, se utilizar una estadística cuya fórmula es similar a la de la varianza:\n\n$$\n    COV(x,y)=\\frac{1}{n-1}\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})\n$$\n\npara el caso muestral. En el caso poblacional, se divide entre $n$ en vez de $n-1$.\n\n---\n\n- Si $COV(x,y) > 0$, entonces $y$ tiende a aumentar cuando lo hace $x$ (relación directa).\n- Si $COV(x,y) < 0$, entonces $y$ tiende a disminuir cuando lo hace $x$ (relación inversa).\n- Si $COV(x,y) \\approx 0$, entonces los puntos se reparten \"equitativamente\" alrededor de $(\\bar{x},\\bar{y})$, es decir, no existe **asociación lineal** entre las variables.\n\n<!---\n\n---\n\nUna propiedad importante de la varianza y la covarianza es\n\n$$\nVAR(x+y) = VAR(x) + 2COV(x,y) + VAR(y)\n$$\n\nNote su similitud con \n\n$$\n(a+b)^2 = a^2 + 2ab + b^2\n$$\n\n--->\n\n---\n\nLa covarianza entre el tamaño del motor y el precio de los carros graficados anteriormente es:\n\n. . .\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5.986403\n```\n:::\n:::\n\n\nInterprete este resultado.\n\n## Propiedades de la covarianza\n\n* $COV(x,y) = COV(y,x)$\n* $COV(a\\ x,y) = a\\ COV(x,y)$ con $a\\in\\mathbb{R}$.\n* $COV(a + x,y) = COV(x,y)$ con $a\\in\\mathbb{R}$.\n\n## Correlación de Pearson\n\nLa **correlación de Pearson** se define como:\n\n$$\nCOR(x,y) = \\frac{COV(x,y)}{SD(x) \\ SD(y)} = \\frac{COV(x,y)}{\\sqrt{VAR(x)}\\sqrt{VAR(y)}}\n$$\n\n---\n\n\nToma valores entre -1 y 1, y su interpretación es más rica que la de la covarianza:\n\n- Es igual a -1: Las dos variables están perfectamente asociadas de manera inversa, es decir, con total seguridad a medida que una aumenta, la otra disminuye.\n- Es cercana a -1: Las variables están asociadas de manera inversa.\n- Es cercana a 0: Las variables no presentan una asociación lineal considerable.\n\n---\n\n\n- Es cercana a 1: Las variables están asociadas de manera directa.\n- Es igual a 1: Las variables están perfectamente asociadas de manera directa, es decir, es decir, con total seguridad a medida que una aumenta, la otra también.\n\n---\n\n\n<p align=\"center\">\n<img src=\"correlaciones.png\" width=\"1100\">\n</p>\n\n\n---\n\nLa correlación (de Pearson) entre el tamaño del motor y el precio de los carros graficados anteriormente es:\n\n. . .\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5974254\n```\n:::\n:::\n\n\nInterprete este resultado.\n\n---\n\n¿Qué diferencias identifican entre la covarianza y la correlación?\n\n. . .\n\n. . .\n\n* Unidades\n* Límites\n\n## Correlación de Spearman\n\nLa correlación se calcula a partir de la covarianza y las varianzas, y estas a su vez, a partir de la media. Por tanto, todas estas estadísticas son sensibles a datos atípicos. Spearman propone una manera de medir correlación basada en rangos que es robusta a datos atípicos:\n\n. . .\n\nLos rangos son simplemente el orden o *ranking* de menor a mayor que se asigna a un conjutno de datos. Por ejemplo:\n\n. . .\n\nDatos:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.266 0.372 0.573 0.908 0.202\n```\n:::\n:::\n\n\n. . .\n\nrangos:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2 3 4 5 1\n```\n:::\n:::\n\n\n---\n\nLa propuesta de Spearman es la siguiente:\n\n\n<p align=\"center\">\n<img src=\"formula_spearman.png\" width=\"800\">\n</p>\n\ndonde $D_i = R(X_i) - R(Y_i)$.\n\n---\n\n**Ejemplo:** Como parte de un estudio sobre el efecto de la presión del grupo sobre el conformismo individual en una situación que implica riesgo monetario, dos investigadores administraron la escala F, una medida de autoritarismo y una escala diseñada para medir estados de lucha social a 12 estudiantes.\n\n---\n\n<p align=\"center\">\n<img src=\"datos_spearman.png\" width=\"800\">\n</p>\n\n---\n\n<p align=\"center\">\n<img src=\"datos2_spearman.png\" width=\"800\">\n</p>\n\n---\n\n<p align=\"center\">\n<img src=\"datos3_spearman.png\" width=\"800\">\n</p>\n\n---\n\nEl coeficiente de correlación de Spearman toma valores entre -1 y 1. Si es cercano a 1, existe una asociación directa entre las dos variables, si es cercano a -1, es asociación inversa.\n\nEste coeficiente de correlación es capaz de identificar correlaciones no lineales **monótonas** de mejor manera que el de Pearson.\n\n---\n\n\nPor ejemplo, para estos datos:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](3.-Descriptiva-Bivariada_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Pearson\"\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.743551\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Spearman\"\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9761896\n```\n:::\n:::\n\n\n---\n\nNo obstante, cuando la tendencia no es monótona:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](3.-Descriptiva-Bivariada_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(\"Pearson\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Pearson\"\n```\n:::\n\n```{.r .cell-code}\ncor(x,y,method = \"pearson\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.01283845\n```\n:::\n\n```{.r .cell-code}\nprint(\"Spearman\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"Spearman\"\n```\n:::\n\n```{.r .cell-code}\ncor(x,y,method = \"spearman\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.07870387\n```\n:::\n:::\n\n\n## $\\tau$ de Kendall\n\nExiste otra propuesta de coeficiente de correlación basada en comparaciones pareadas de los $n$ individuos. Sean $(x_i,y_i)$ las observados en el $i$-ésimo individuo de las variables $X$ y $Y$, respectivamente. \n\n. . .\n\nSe empareja cada individuo $i$ con todos los demás $j$ y en cada caso, se evalúa si son concordantes o discordantes. Son concordantes si $x_i<x_j$ y $y_i<y_j$, o si $x_i>x_j$ y $y_i>y_j$. Son discordantes si $x_i<x_j$ y $y_i>y_j$, o si $x_i>x_j$ y $y_i<y_j$.\n\n---\n\nFinalmente se calcula el coeficiente $\\tau$ de Kendall como\n\n$$\nT = \\frac{\\#pares\\ concordante - \\#pares\\ discordantes}{total\\ de\\ pares} \n$$\n\n$$\n= \\frac{2(\\#pares\\ concordante - \\#pares\\ discordantes)}{N(N-1)}\n$$\n\n\n---\n\nEl coeficiente de correlación $\\tau$ de Kendall toma valores entre -1 y 1 y su interpretación es análoga a la del coeficiente de correlación de Pearson.\n\n. . .\n\nNote que este coeficiente se puede aplicar con variables de tipo ordinal, no necesariamente cuantitativas. Esa es su principal ventaja.\n\n---\n\nSuponga que se tienen los siguientes datos:\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n   x  y\n1 68 43\n2 39 14\n3  1 82\n4 34 59\n5 87 51\n```\n:::\n:::\n\n\nHaga una tabla de $5\\times 5$ que muestra si cada par es concordante o discordante.\n\n. . .\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n  1     2     3     4     5 \n1 \"\"    \"\"    \"\"    \"\"    \"\"\n2 \"Con\" \"\"    \"\"    \"\"    \"\"\n3 \"Dis\" \"Dis\" \"\"    \"\"    \"\"\n4 \"Dis\" \"Dis\" \"Dis\" \"\"    \"\"\n5 \"Con\" \"Con\" \"Dis\" \"Dis\" \"\"\n```\n:::\n:::\n\n\n---\n\nA partir de la tabla, calcule el coeficiente de correlación $\\tau$ de Kendall:\n\n* Número de concordantes: 3\n* Número de discordantes: 7\n* Total de pares: 10\n\n. . .\n\n$$\nT = \\frac{3 - 7}{10} = -0,4\n$$\n\n# Referencias{.center}\n\n-Rangel, J. (2022). Introducción a la estadística descriptiva [Diapositivas de presentación].\n\n-Peña, D. (2014). Fundamentos de estadística. Alianza editorial.\n\n-Buitrago, L., & Sosa, J. (s.f.). Introducción a la Estadística. Recuperado de https://rpubs.com/jcsosam/803558",
    "supporting": [
      "3.-Descriptiva-Bivariada_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}